{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLokDKoN1aKv"
   },
   "source": [
    "# Using Ragas to Evaluate a RAG Application built with LangChain and LangGraph\n",
    "\n",
    "In the following notebook, we'll be looking at how [Ragas](https://github.com/explodinggradients/ragas) can be helpful in a number of ways when looking to evaluate your RAG applications!\n",
    "\n",
    "While this example is rooted in LangChain/LangGraph - Ragas is framework agnostic (you don't even need to be using a framework!).\n",
    "\n",
    "- ðŸ¤ Breakout Room #1\n",
    "  1. Task 1: Installing Required Libraries\n",
    "  2. Task 2: Set Environment Variables\n",
    "  3. Task 3: Synthetic Dataset Generation for Evaluation using Ragas\n",
    "  4. Task 4: Evaluating our Pipeline with Ragas\n",
    "  5. Task 6: Making Adjustments and Re-Evaluating\n",
    "\n",
    "But first! Let's set some dependencies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k9tqHdq2BGi"
   },
   "source": [
    "## Dependencies and API Keys:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3d5seTX2xyx"
   },
   "source": [
    "We'll also need to provide our API keys.\n",
    "\n",
    "First, OpenAI's for our LLM/embedding model combination!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Ragas Authentication\n",
    "# Choose one of the options below:\n",
    "\n",
    "# Option 1: Use Ragas Cloud (requires token from https://cloud.ragas.io/)\n",
    "# os.environ[\"RAGAS_APP_TOKEN\"] = getpass(\"Please enter your Ragas App Token!\")\n",
    "\n",
    "# Option 2: Disable cloud features to avoid authentication\n",
    "os.environ[\"RAGAS_DO_NOT_TRACK\"] = \"true\"\n",
    "\n",
    "print(\"Ragas authentication configured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Please enter your OpenAI API key!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zTz1-4U3Hg0"
   },
   "source": [
    "## Generating Synthetic Test Data\n",
    "\n",
    "We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n",
    "\n",
    "> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "We'll prepare our data - which should hopefull be familiar at this point since it's our Loan Data use-case!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "\n",
    "path = \"data/\"\n",
    "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfyA65MM4Tbn"
   },
   "source": [
    "### Knowledge Graph Based Synthetic Generation\n",
    "\n",
    "Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n",
    "\n",
    "Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbZ9j1EL-X55"
   },
   "source": [
    "### Abstracted SDG\n",
    "\n",
    "The above method is the full process - but we can shortcut that using the provided abstractions!\n",
    "\n",
    "This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea6d547381b4a1483a1cddfac287bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5305bbd5f36d4aa2a5a757b16362d4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b2d65aeac944ebaadf5e93ae305048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '72e71b'. Skipping!\n",
      "Property 'summary' already exists in node 'f7842f'. Skipping!\n",
      "Property 'summary' already exists in node '67bf4c'. Skipping!\n",
      "Property 'summary' already exists in node '73400b'. Skipping!\n",
      "Property 'summary' already exists in node 'b98424'. Skipping!\n",
      "Property 'summary' already exists in node 'efb1b8'. Skipping!\n",
      "Property 'summary' already exists in node 'a012fb'. Skipping!\n",
      "Property 'summary' already exists in node 'caad3e'. Skipping!\n",
      "Property 'summary' already exists in node 'b07b90'. Skipping!\n",
      "Property 'summary' already exists in node '73b2ba'. Skipping!\n",
      "Property 'summary' already exists in node '428044'. Skipping!\n",
      "Property 'summary' already exists in node 'b5fe53'. Skipping!\n",
      "Property 'summary' already exists in node 'f2ae6a'. Skipping!\n",
      "Property 'summary' already exists in node '27b8a5'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31c3ae4147b45209787a31e52e14ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff74f245494f40b6a283a9fa8e6673dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node '73400b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '72e71b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b98424'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '27b8a5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'caad3e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '67bf4c'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'a012fb'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f7842f'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'efb1b8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b5fe53'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b07b90'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '73b2ba'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f2ae6a'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '428044'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a15415b230f4243a4b0e440bebf27f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e87f4f3999046a587b3c5971cb0acbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966d18d71d84441581e09ac7ca464bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0053663ea7f42ae9c1c9e8f1189bbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs[:20], testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is BBAY 1 for direct loan annual loan lim...</td>\n",
       "      <td>[non-term (includes clock-hour calendars), or ...</td>\n",
       "      <td>BBAY 1 is one of the options that can be used ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are osteopathic clinical periods eligible to b...</td>\n",
       "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
       "      <td>Yes, required clinical periods in osteopathic ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How FWS work with payment periods, it same lik...</td>\n",
       "      <td>[Non-Term Characteristics A program that measu...</td>\n",
       "      <td>The payment period is applicable to all Title ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where can I find information on Direct Loan an...</td>\n",
       "      <td>[both the credit or clock hours and the weeks ...</td>\n",
       "      <td>For information on Direct Loan annual loan lim...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Under what conditions can a practicum or clini...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>A practicum or clinical experience required fo...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If a medical or education program requires all...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>A medical or education program that requires a...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If a medical or education program requires all...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>A medical or education program that requires a...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If a medical program requires a practicum or c...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>If all students in a medical program are requi...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What are the requirements for Direct Loan disb...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
       "      <td>In subscription-based programs, for the first ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do the requirements for Direct Loan disbur...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nnon-term (includes clock-hour cale...</td>\n",
       "      <td>In subscription-based programs, for the first ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How do the requirements for Pell Grant disburs...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nnon-term (includes clock-hour cale...</td>\n",
       "      <td>In standard term and nonstandard term academic...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>how volume 2 chapter 2 and volume 8 chapter 3 ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nnon-term (includes clock-hour cale...</td>\n",
       "      <td>volume 2 chapter 2 gives detail on subscriptio...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   what is BBAY 1 for direct loan annual loan lim...   \n",
       "1   Are osteopathic clinical periods eligible to b...   \n",
       "2   How FWS work with payment periods, it same lik...   \n",
       "3   Where can I find information on Direct Loan an...   \n",
       "4   Under what conditions can a practicum or clini...   \n",
       "5   If a medical or education program requires all...   \n",
       "6   If a medical or education program requires all...   \n",
       "7   If a medical program requires a practicum or c...   \n",
       "8   What are the requirements for Direct Loan disb...   \n",
       "9   How do the requirements for Direct Loan disbur...   \n",
       "10  How do the requirements for Pell Grant disburs...   \n",
       "11  how volume 2 chapter 2 and volume 8 chapter 3 ...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [non-term (includes clock-hour calendars), or ...   \n",
       "1   [Inclusion of Clinical Work in a Standard Term...   \n",
       "2   [Non-Term Characteristics A program that measu...   \n",
       "3   [both the credit or clock hours and the weeks ...   \n",
       "4   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "5   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "6   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "7   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "8   [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
       "9   [<1-hop>\\n\\nnon-term (includes clock-hour cale...   \n",
       "10  [<1-hop>\\n\\nnon-term (includes clock-hour cale...   \n",
       "11  [<1-hop>\\n\\nnon-term (includes clock-hour cale...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   BBAY 1 is one of the options that can be used ...   \n",
       "1   Yes, required clinical periods in osteopathic ...   \n",
       "2   The payment period is applicable to all Title ...   \n",
       "3   For information on Direct Loan annual loan lim...   \n",
       "4   A practicum or clinical experience required fo...   \n",
       "5   A medical or education program that requires a...   \n",
       "6   A medical or education program that requires a...   \n",
       "7   If all students in a medical program are requi...   \n",
       "8   In subscription-based programs, for the first ...   \n",
       "9   In subscription-based programs, for the first ...   \n",
       "10  In standard term and nonstandard term academic...   \n",
       "11  volume 2 chapter 2 gives detail on subscriptio...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ni4Q14_arJYw"
   },
   "source": [
    "## LangChain RAG\n",
    "\n",
    "Now we'll construct our LangChain RAG, which we will be evaluating using the above created test data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGy99jkVrVqX"
   },
   "source": [
    "### R - Retrieval\n",
    "\n",
    "Let's start with building our retrieval pipeline, which will involve loading the same data we used to create our synthetic test set above.\n",
    "\n",
    "> NOTE: We need to use the same data - as our test set is specifically designed for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/\"\n",
    "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQv3Psil_D2A"
   },
   "source": [
    "Now that we have our data loaded, let's split it into chunks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1102"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "len(split_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â“ Question: \n",
    "\n",
    "What is the purpose of the `chunk_overlap` parameter in the `RecursiveCharacterTextSplitter`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### âœ… Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk_overlap parameter serves several critical purposes in document chunking:\n",
    "\n",
    "**Context Preservation**: Maintains continuity between adjacent chunks by including overlapping text, preventing loss of context at chunk boundaries\n",
    "\n",
    "**Semantic Coherence**: Ensures that sentences or concepts that span across chunk boundaries remain accessible in both chunks\n",
    "\n",
    "**Improved Retrieval**: Increases the likelihood that relevant information is captured during retrieval, even if a query relates to content near chunk boundaries\n",
    "\n",
    "**Reduced Information Loss**: Prevents important relationships or context from being lost when documents are split into smaller pieces\n",
    "\n",
    "**Better Embedding Quality**: Overlapping content provides richer context for embedding generation, leading to more accurate semantic representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EcbmBBC_G2s"
   },
   "source": [
    "Next up, we'll need to provide an embedding model that we can use to construct our vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AP_VDgyx_MPq"
   },
   "source": [
    "Now we can build our in memory QDrant vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"loan_data\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"loan_data\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUSCXe7x_h0O"
   },
   "source": [
    "We can now add our documents to our vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = vector_store.add_documents(documents=split_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBgsT5_m_lOD"
   },
   "source": [
    "Let's define our retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZX68nle_nUm"
   },
   "source": [
    "Now we can produce a node for retrieval!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "  retrieved_docs = retriever.invoke(state[\"question\"])\n",
    "  return {\"context\" : retrieved_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48-mJHgUsvDG"
   },
   "source": [
    "### Augmented\n",
    "\n",
    "Let's create a simple RAG prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "You are a helpful assistant who answers questions based on provided context. You must only use the provided context, and cannot use your own knowledge.\n",
    "\n",
    "### Question\n",
    "{question}\n",
    "\n",
    "### Context\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cznU20c0uY9j"
   },
   "source": [
    "### Generation\n",
    "\n",
    "We'll also need an LLM to generate responses - we'll use `gpt-4o-nano` to avoid using the same model as our judge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTpV7-b7_44n"
   },
   "source": [
    "Then we can create a `generate` node!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "  docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "  messages = rag_prompt.format_messages(question=state[\"question\"], context=docs_content)\n",
    "  response = llm.invoke(messages)\n",
    "  return {\"response\" : response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhD1IxvXu2zX"
   },
   "source": [
    "### Building RAG Graph with LangGraph\n",
    "\n",
    "Let's create some state for our LangGraph RAG graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class State(TypedDict):\n",
    "  question: str\n",
    "  context: List[Document]\n",
    "  response: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFEqEQje_--V"
   },
   "source": [
    "Now we can build our simple graph!\n",
    "\n",
    "> NOTE: We're using `add_sequence` since we will always move from retrieval to generation. This is essentially building a chain in LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKX8yupqAIeQ"
   },
   "source": [
    "Let's do a test to make sure it's doing what we'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"question\" : \"What are the different kinds of loans?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, the different kinds of loans mentioned are:\\n\\n1. Direct Loan\\n2. Direct Unsubsidized Loan\\n\\nThe context specifically references these types when discussing loan counseling, eligibility, and repayment options.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK5gyOlixWr4"
   },
   "source": [
    "## Evaluating the App with Ragas\n",
    "\n",
    "Now we can finally do our evaluation!\n",
    "\n",
    "We'll start by running the queries we generated usign SDG above through our application to get context and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_row in dataset:\n",
    "  response = graph.invoke({\"question\" : test_row.eval_sample.user_input})\n",
    "  test_row.eval_sample.response = response[\"response\"]\n",
    "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"BBAY 1 for a direct loan refers to a specific academic period used to monitor and reset a student's annual loan limit eligibility. When BBAY 1 has elapsed, a student regains eligibility for a new annual loan limit, allowing them to receive additional loans. Alternating an SAY (Scheduled Academic Year) with BBAY 1 can enable a student to receive a loan sooner than with an SAY alone, especially in cases where the student wants to access summer loans earlier in the academic year.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.samples[0].eval_sample.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TULcXSm0AUe0"
   },
   "source": [
    "Then we can convert that table into a `EvaluationDataset` which will make the process of evaluation smoother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQibuzfZAbvA"
   },
   "source": [
    "We'll need to select a judge model - in this case we're using the same model that was used to generate our Synthetic Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzHuOZgBAoUU"
   },
   "source": [
    "Next up - we simply evaluate on our desired metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92e526968764527bb32f7b3c2090f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[65]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.8729, 'faithfulness': 0.9335, 'factual_correctness': 0.6300, 'answer_relevancy': 0.9544, 'context_entity_recall': 0.2911, 'noise_sensitivity_relevant': 0.2839}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
    "from ragas import evaluate, RunConfig\n",
    "\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZxxr2NqAyBp"
   },
   "source": [
    "## Making Adjustments and Re-Evaluating\n",
    "\n",
    "Now that we've got our baseline - let's make a change and see how the model improves or doesn't improve!\n",
    "\n",
    "> NOTE: This will be using Cohere's Rerank model - please be sure to [sign-up for an API key!](https://docs.cohere.com/reference/about)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"COHERE_API_KEY\"] = getpass(\"Please enter your Cohere API key!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We'll first set our retriever to return more documents, which will allow us to take advantage of the reranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_example_retriever = vector_store.as_retriever(search_kwargs={\"k\": 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reranking, or contextual compression, is a technique that uses a reranker to compress the retrieved documents into a smaller set of documents.\n",
    "\n",
    "This is essentially a slower, more accurate form of semantic similarity that we use on a smaller subset of our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "def retrieve_adjusted(state):\n",
    "  compressor = CohereRerank(model=\"rerank-v3.5\")\n",
    "  compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=adjusted_example_retriever, search_kwargs={\"k\": 5}\n",
    "  )\n",
    "  retrieved_docs = compression_retriever.invoke(state[\"question\"])\n",
    "  return {\"context\" : retrieved_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply rebuild our graph with the new retriever!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjustedState(TypedDict):\n",
    "  question: str\n",
    "  context: List[Document]\n",
    "  response: str\n",
    "\n",
    "adjusted_graph_builder = StateGraph(AdjustedState).add_sequence([retrieve_adjusted, generate])\n",
    "adjusted_graph_builder.add_edge(START, \"retrieve_adjusted\")\n",
    "adjusted_graph = adjusted_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context mentions two specific types of loans: Federal PLUS Loans and Direct Loans (which include Direct Subsidized Loans and Direct Unsubsidized Loans). However, it does not explicitly list all the different kinds of loans. Based on the information provided, the different kinds of loans include:\\n\\n1. Federal PLUS Loans (including student Direct PLUS Loans)\\n2. Direct Subsidized Loans\\n3. Direct Unsubsidized Loans\\n\\nAdditionally, there are references to loans made under the Federal Family Education Loan (FFEL) Program before it ended, which indicates there were other FFEL Program loans, but they are not explicitly named in the provided text.\\n\\nTherefore, the different kinds of loans mentioned are:\\n- Federal PLUS Loans\\n- Direct Subsidized Loans\\n- Direct Unsubsidized Loans'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = adjusted_graph.invoke({\"question\" : \"What are the different kinds of loans?\"})\n",
    "response[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "rerank_dataset = copy.deepcopy(dataset)\n",
    "\n",
    "for test_row in rerank_dataset:\n",
    "  response = adjusted_graph.invoke({\"question\" : test_row.eval_sample.user_input})\n",
    "  test_row.eval_sample.response = response[\"response\"]\n",
    "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
    "  time.sleep(2) # To try to avoid rate limiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"BBAY 1 for direct loan annual loan limit progression is an alternative to the Scheduled Academic Year (SAY) used to monitor a student's annual loan limit. Specifically, for credit-hour programs with an SAY, BBAY 1 must include the same number of terms as the SAY (excluding any summer trailer or header). The BBAY 1 period can include terms the student does not attend if the student could have enrolled at least half-time in those terms, but it must start with a term in which the student was enrolled.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank_dataset.samples[0].eval_sample.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_evaluation_dataset = EvaluationDataset.from_pandas(rerank_dataset.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8893f2e0b6411caae25bbed796ed9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.8347, 'faithfulness': 0.9581, 'factual_correctness': 0.7033, 'answer_relevancy': 0.8763, 'context_entity_recall': 0.4972, 'noise_sensitivity_relevant': 0.2600}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = evaluate(\n",
    "    dataset=rerank_evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â“ Question: \n",
    "\n",
    "Which system performed better, on what metrics, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### âœ… Answer:\n",
    "\n",
    "âœ… Reranking Victories:\n",
    "\n",
    "Factual Correctness: +7.33% (63.00% â†’ 70.33%) - Significant improvement!\n",
    "Context Entity Recall: +20.61% (29.11% â†’ 49.72%) - Massive improvement!\n",
    "Faithfulness: +2.46% (93.35% â†’ 95.81%) - Small but meaningful gain\n",
    "Noise Sensitivity: -2.39% (lower is better) - Better focus\n",
    "\n",
    "âš ï¸ Baseline Advantages:\n",
    "\n",
    "Answer Relevancy: -7.81% (95.44% â†’ 87.63%) - Notable decrease\n",
    "Context Recall: -3.82% (87.29% â†’ 83.47%) - Some context loss\n",
    "\n",
    "ðŸ” What This Tells Us:\n",
    "\n",
    "Reranking successfully improved content quality - especially factual accuracy and entity coverage\n",
    "The trade-off was retrieval completeness - some relevant context was lost in compression\n",
    "Quality vs. Quantity tension - classic information retrieval challenge\n",
    "\n",
    "This is actually a success story for reranking - it achieved the goal of improving factual correctness while maintaining high faithfulness. The decision between systems would depend on whether you prioritize accuracy (reranking) or comprehensive relevancy (baseline)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
