{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCk2Rx4cjlYF"
   },
   "source": [
    "# Synthetic Data Generation Using RAGAS - RAG Evaluation with LangSmith\n",
    "\n",
    "In the following notebook we'll explore a use-case for RAGAS' synthetic testset generation workflow!\n",
    "\n",
    "\n",
    "\n",
    "- ðŸ¤ BREAKOUT ROOM #1\n",
    "  1. Use RAGAS to Generate Synthetic Data\n",
    "\n",
    "- ðŸ¤ BREAKOUT ROOM #2\n",
    "  1. Load them into a LangSmith Dataset\n",
    "  2. Evaluate our RAG chain against the synthetic test data\n",
    "  3. Make changes to our pipeline\n",
    "  4. Evaluate the modified pipeline\n",
    "\n",
    "SDG is a critical piece of the puzzle, especially for early iteration! Without it, it would not be nearly as easy to get high quality early signal for our application's performance.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bG2ta-B478G"
   },
   "source": [
    "# ðŸ¤ BREAKOUT ROOM #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VUI7vF_kbv9"
   },
   "source": [
    "## Task 1: Dependencies and API Keys\n",
    "\n",
    "We'll need to install a number of API keys and dependencies, since we'll be leveraging a number of great technologies for this pipeline!\n",
    "\n",
    "1. OpenAI's endpoints to handle the Synthetic Data Generation\n",
    "2. OpenAI's Endpoints for our RAG pipeline and LangSmith evaluation\n",
    "3. QDrant as our vectorstore\n",
    "4. LangSmith for our evaluation coordinator!\n",
    "\n",
    "Let's install and provide all the required information below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and API Keys:\n",
    "\n",
    "> NOTE: DO NOT RUN THESE CELLS IF YOU ARE RUNNING THIS NOTEBOOK LOCALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m175.7/175.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install -qU ragas==0.2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU langchain-community==0.3.14 langchain-openai==0.2.14 unstructured==0.16.12 langgraph==0.2.61 langchain-qdrant==0.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Import\n",
    "\n",
    "To prevent errors that may occur based on OS - we'll import NLTK and download the needed packages to ensure correct handling of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nilayjhaveri/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nilayjhaveri/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also want to set a project name to make things easier for ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - SDG - {uuid4().hex[0:8]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI's API Key!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Test Data\n",
    "\n",
    "We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n",
    "\n",
    "> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "We'll prepare our data - which should hopefull be familiar at this point since it's our Loan Data use-case!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "\n",
    "path = \"data/\"\n",
    "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph Based Synthetic Generation\n",
    "\n",
    "Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n",
    "\n",
    "Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrolled SDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to instantiate our Knowledge Graph.\n",
    "\n",
    "This graph will contain N number of nodes that have M number of relationships. These nodes and relationships (AKA \"edges\") will define our knowledge graph and be used later to construct relevant questions and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 0, relationships: 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step we're going to take is to simply insert each of our full documents into the graph. This will provide a base that we can apply transformations to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 20, relationships: 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "### NOTICE: We're using a subset of the data for this example - this is to keep costs/time down.\n",
    "\n",
    "for doc in docs[:20]:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll apply the *default* transformations to our knowledge graph. This will take the nodes currently on the graph and transform them based on a set of [default transformations](https://docs.ragas.io/en/latest/references/transforms/#ragas.testset.transforms.default_transforms).\n",
    "\n",
    "These default transformations are dependent on the corpus length, in our case:\n",
    "\n",
    "- Producing Summaries -> produces summaries of the documents\n",
    "- Extracting Headlines -> finding the overall headline for the document\n",
    "- Theme Extractor -> extracts broad themes about the documents\n",
    "\n",
    "It then uses cosine-similarity and heuristics between the embeddings of the above transformations to construct relationships between the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba61e0098324806a9bcb5931fa00838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0bdf32c1124749b4ea2ffc6a494c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba3e0bcfae74ec7b93f0c5895e09cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '7e5072'. Skipping!\n",
      "Property 'summary' already exists in node '97fc74'. Skipping!\n",
      "Property 'summary' already exists in node '591565'. Skipping!\n",
      "Property 'summary' already exists in node 'db0b93'. Skipping!\n",
      "Property 'summary' already exists in node '1f5fca'. Skipping!\n",
      "Property 'summary' already exists in node '31c303'. Skipping!\n",
      "Property 'summary' already exists in node 'a47535'. Skipping!\n",
      "Property 'summary' already exists in node 'b65d1b'. Skipping!\n",
      "Property 'summary' already exists in node 'c692ec'. Skipping!\n",
      "Property 'summary' already exists in node '5854bb'. Skipping!\n",
      "Property 'summary' already exists in node '195de4'. Skipping!\n",
      "Property 'summary' already exists in node 'e87247'. Skipping!\n",
      "Property 'summary' already exists in node 'b1f8cb'. Skipping!\n",
      "Property 'summary' already exists in node '027815'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e673d5e0f974691891282025c7ddf14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d50c2ce70db47899e0d5bbb5d353a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node '1f5fca'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7e5072'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'a47535'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '5854bb'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'db0b93'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '591565'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '97fc74'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '027815'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '31c303'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '195de4'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e87247'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b1f8cb'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b65d1b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'c692ec'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b771e7ca3954151be335f9f717f072d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 40, relationships: 480)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "transformer_llm = generator_llm\n",
    "embedding_model = generator_embeddings\n",
    "\n",
    "default_transforms = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n",
    "apply_transforms(kg, default_transforms)\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save and load our knowledge graphs as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 40, relationships: 480)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.save(\"loan_data_kg.json\")\n",
    "loan_data_kg = KnowledgeGraph.load(\"loan_data_kg.json\")\n",
    "loan_data_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our knowledge graph, we can construct a \"test set generator\" - which will allow us to create queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=loan_data_kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we'd like to be able to define the kinds of queries we're generating - which is made simple by Ragas having pre-created a number of different \"QuerySynthesizer\"s.\n",
    "\n",
    "Each of these Synthetsizers is going to tackle a separate kind of query which will be generated from a scenario and a persona.\n",
    "\n",
    "In essence, Ragas will use an LLM to generate a persona of someone who would interact with the data - and then use a scenario to construct a question from that data and persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import default_query_distribution, SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
    "\n",
    "query_distribution = [\n",
    "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "        (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "        (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â“ Question #1:\n",
    "\n",
    "What are the three types of query synthesizers doing? Describe each one in simple terms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### âœ… Answer:\n",
    "\n",
    "**SingleHopSpecificQuerySynthesizer** - This generates straightforward, direct queries that can be answered with a single step or \"hop\" through the data. These are specific, focused questions that don't require complex reasoning or multiple data points to answer.\n",
    "\n",
    "**MultiHopAbstractQuerySynthesizer** - This creates more complex queries that require multiple steps or \"hops\" to answer, but the questions are abstract in nature. These queries might need to connect different pieces of information or require higher-level reasoning to resolve.\n",
    "\n",
    "**MultiHopSpecificQuerySynthesizer** - This generates complex queries that require multiple steps to answer, but unlike the abstract version, these queries are specific and concrete. They need multiple data points or reasoning steps but ask for precise, specific information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use our `TestSetGenerator` to generate our testset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b528d508b4460ea858c46c8bf05e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e026ffec2134fe5a8835998f2fa95d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd8fc099aee4877ab011042c5201556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are academic years in school?</td>\n",
       "      <td>[Chapter 1 Academic Years, Academic Calendars,...</td>\n",
       "      <td>Chapter 1 Academic Years, Academic Calendars, ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is 34 CFR 668.3(a) about?</td>\n",
       "      <td>[Regulatory Citations Academic year minimums: ...</td>\n",
       "      <td>34 CFR 668.3(a) relates to the academic year m...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Volume 8 in relation to clinical work ...</td>\n",
       "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
       "      <td>Inclusion of Clinical Work in a Standard Term:...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are Non-Term Characteristics in relation ...</td>\n",
       "      <td>[Non-Term Characteristics A program that measu...</td>\n",
       "      <td>A program that measures progress in credit-hou...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the misspelled term related to student...</td>\n",
       "      <td>[both the credit or clock hours and the weeks ...</td>\n",
       "      <td>The term is 'Direct Loan'.</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Based on the guidance and regulations for Titl...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>Disbursement timing in clock-hour or non-term ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do non-term characteristics like clock-hou...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>Non-term characteristics such as measuring pro...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does the inclusion of clinical work outsid...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>The inclusion of clinical work conducted outsi...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do Chapters 2 and 3 collectively inform th...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>Chapter 2 explains that clinical work conducte...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Volume 2 and Volume 7 how relate to credit hou...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>Volume 2 explains that the credit or clock hou...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How do Volume 7 and Volume 8 relate to the dis...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>Volume 7 explains that the amount of Pell Gran...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0                  What are academic years in school?   \n",
       "1                      What is 34 CFR 668.3(a) about?   \n",
       "2   What is Volume 8 in relation to clinical work ...   \n",
       "3   What are Non-Term Characteristics in relation ...   \n",
       "4   What is the misspelled term related to student...   \n",
       "5   Based on the guidance and regulations for Titl...   \n",
       "6   How do non-term characteristics like clock-hou...   \n",
       "7   How does the inclusion of clinical work outsid...   \n",
       "8   How do Chapters 2 and 3 collectively inform th...   \n",
       "9   Volume 2 and Volume 7 how relate to credit hou...   \n",
       "10  How do Volume 7 and Volume 8 relate to the dis...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Chapter 1 Academic Years, Academic Calendars,...   \n",
       "1   [Regulatory Citations Academic year minimums: ...   \n",
       "2   [Inclusion of Clinical Work in a Standard Term...   \n",
       "3   [Non-Term Characteristics A program that measu...   \n",
       "4   [both the credit or clock hours and the weeks ...   \n",
       "5   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "6   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "7   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "8   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "9   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "10  [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   Chapter 1 Academic Years, Academic Calendars, ...   \n",
       "1   34 CFR 668.3(a) relates to the academic year m...   \n",
       "2   Inclusion of Clinical Work in a Standard Term:...   \n",
       "3   A program that measures progress in credit-hou...   \n",
       "4                          The term is 'Direct Loan'.   \n",
       "5   Disbursement timing in clock-hour or non-term ...   \n",
       "6   Non-term characteristics such as measuring pro...   \n",
       "7   The inclusion of clinical work conducted outsi...   \n",
       "8   Chapter 2 explains that clinical work conducte...   \n",
       "9   Volume 2 explains that the credit or clock hou...   \n",
       "10  Volume 7 explains that the amount of Pell Gran...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   single_hop_specifc_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstracted SDG\n",
    "\n",
    "The above method is the full process - but we can shortcut that using the provided abstractions!\n",
    "\n",
    "This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbddd4ab35646ea9101093445632659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7b3d9a5b0c48b28f38dac4dca7bb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4988355dea9b4a0a9136a8ba0b5aa40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '0a2726'. Skipping!\n",
      "Property 'summary' already exists in node '8d0cc3'. Skipping!\n",
      "Property 'summary' already exists in node '5d2301'. Skipping!\n",
      "Property 'summary' already exists in node 'cf2ab0'. Skipping!\n",
      "Property 'summary' already exists in node '6c5572'. Skipping!\n",
      "Property 'summary' already exists in node 'd1e11d'. Skipping!\n",
      "Property 'summary' already exists in node '45b047'. Skipping!\n",
      "Property 'summary' already exists in node '8fb9f9'. Skipping!\n",
      "Property 'summary' already exists in node '9687d0'. Skipping!\n",
      "Property 'summary' already exists in node '2e212f'. Skipping!\n",
      "Property 'summary' already exists in node '0643b6'. Skipping!\n",
      "Property 'summary' already exists in node '9b88b2'. Skipping!\n",
      "Property 'summary' already exists in node 'ae0bcf'. Skipping!\n",
      "Property 'summary' already exists in node 'e79ced'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6a2fd63241479995e91500072f911e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac048dceada42c2a60f9388816cc020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node '0a2726'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '5d2301'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ae0bcf'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '9687d0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'cf2ab0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '45b047'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8d0cc3'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '0643b6'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '6c5572'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '2e212f'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e79ced'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8fb9f9'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '9b88b2'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd1e11d'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c662d8591740d796bc9af0d9638671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0615d89c95eb4b238d654bdae984239c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a90011fcfa46b08cc526a304c1750d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b54b89c50124a1c8be94ea1c767df04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs[:20], testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the role of the School Participation D...</td>\n",
       "      <td>[Chapter 1 Academic Years, Academic Calendars,...</td>\n",
       "      <td>The context does not specify the exact role of...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you please explain the significance of 3...</td>\n",
       "      <td>[Regulatory Citations Academic year minimums: ...</td>\n",
       "      <td>Regulatory Citations Academic year minimums: 3...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Chaptr 3?</td>\n",
       "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
       "      <td>Inclusion of Clinical Work in a Standard Term ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FWS is it like a payment period or not and how...</td>\n",
       "      <td>[Non-Term Characteristics A program that measu...</td>\n",
       "      <td>The payment period is applicable to all Title ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does completing additional hours or weeks ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>Completing additional weeks of instructional t...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wht are the weeks of instrctional time reuired...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nChapter 1 Academic Years, Academic...</td>\n",
       "      <td>The context states that for credit-hour progra...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do credit-hour and clock-hour programs dif...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nChapter 1 Academic Years, Academic...</td>\n",
       "      <td>Credit-hour programs must have an academic yea...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does the inclusion of clinical work in sta...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>The inclusion of clinical work in standard ter...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do Appendix A and Appendix B guide the dis...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
       "      <td>Appendix B provides detailed guidance on disbu...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does Volume 8 explain the impact of accele...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>Volume 8 details that in clock-hour or non-ter...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Considering the disbursement timing rules for ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
       "      <td>The inclusion of clinical work conducted outsi...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How do Chapters 2 and 3 collectively address t...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nChapter 1 Academic Years, Academic...</td>\n",
       "      <td>Chapter 2 discusses the inclusion of clinical ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   What is the role of the School Participation D...   \n",
       "1   Could you please explain the significance of 3...   \n",
       "2                                   What is Chaptr 3?   \n",
       "3   FWS is it like a payment period or not and how...   \n",
       "4   How does completing additional hours or weeks ...   \n",
       "5   Wht are the weeks of instrctional time reuired...   \n",
       "6   How do credit-hour and clock-hour programs dif...   \n",
       "7   How does the inclusion of clinical work in sta...   \n",
       "8   How do Appendix A and Appendix B guide the dis...   \n",
       "9   How does Volume 8 explain the impact of accele...   \n",
       "10  Considering the disbursement timing rules for ...   \n",
       "11  How do Chapters 2 and 3 collectively address t...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Chapter 1 Academic Years, Academic Calendars,...   \n",
       "1   [Regulatory Citations Academic year minimums: ...   \n",
       "2   [Inclusion of Clinical Work in a Standard Term...   \n",
       "3   [Non-Term Characteristics A program that measu...   \n",
       "4   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "5   [<1-hop>\\n\\nChapter 1 Academic Years, Academic...   \n",
       "6   [<1-hop>\\n\\nChapter 1 Academic Years, Academic...   \n",
       "7   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "8   [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
       "9   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "10  [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
       "11  [<1-hop>\\n\\nChapter 1 Academic Years, Academic...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The context does not specify the exact role of...   \n",
       "1   Regulatory Citations Academic year minimums: 3...   \n",
       "2   Inclusion of Clinical Work in a Standard Term ...   \n",
       "3   The payment period is applicable to all Title ...   \n",
       "4   Completing additional weeks of instructional t...   \n",
       "5   The context states that for credit-hour progra...   \n",
       "6   Credit-hour programs must have an academic yea...   \n",
       "7   The inclusion of clinical work in standard ter...   \n",
       "8   Appendix B provides detailed guidance on disbu...   \n",
       "9   Volume 8 details that in clock-hour or non-ter...   \n",
       "10  The inclusion of clinical work conducted outsi...   \n",
       "11  Chapter 2 discusses the inclusion of clinical ...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vSRr2MXk0P_"
   },
   "source": [
    "We'll need to provide our LangSmith API key, and set tracing to \"true\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLDUsLJg43k7"
   },
   "source": [
    "# ðŸ¤ BREAKOUT ROOM #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SLtk1GtnyoY"
   },
   "source": [
    "## Task 4: LangSmith Dataset\n",
    "\n",
    "Now we can move on to creating a dataset for LangSmith!\n",
    "\n",
    "First, we'll need to create a dataset on LangSmith using the `Client`!\n",
    "\n",
    "We'll name our Dataset to make it easy to work with later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"Loan Synthetic Data\"\n",
    "\n",
    "langsmith_dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Loan Synthetic Data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64SmXMBnzXWm"
   },
   "source": [
    "We'll iterate through the RAGAS created dataframe - and add each example to our created dataset!\n",
    "\n",
    "> NOTE: We need to conform the outputs to the expected format - which in this case is: `question` and `answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_row in dataset.to_pandas().iterrows():\n",
    "  client.create_example(\n",
    "      inputs={\n",
    "          \"question\": data_row[1][\"user_input\"]\n",
    "      },\n",
    "      outputs={\n",
    "          \"answer\": data_row[1][\"reference\"]\n",
    "      },\n",
    "      metadata={\n",
    "          \"context\": data_row[1][\"reference_contexts\"]\n",
    "      },\n",
    "      dataset_id=langsmith_dataset.id\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6EbQVyZq-2j"
   },
   "source": [
    "## Basic RAG Chain\n",
    "\n",
    "Time for some RAG!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_documents = docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQorBy8H1AZR"
   },
   "source": [
    "To keep things simple, we'll just use LangChain's recursive character text splitter!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "rag_documents = text_splitter.split_documents(rag_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kghuTb9R01oO"
   },
   "source": [
    "We'll create our vectorstore using OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpCLS-a01Ft2"
   },
   "source": [
    "As usual, we will power our RAG application with Qdrant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=rag_documents,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"Loan RAG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxUOMaQX1K2N"
   },
   "source": [
    "To get the \"A\" in RAG, we'll provide a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "Given a provided context and question, you must answer the question based only on context.\n",
    "\n",
    "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZnHDh4e1Ou5"
   },
   "source": [
    "For our LLM, we will be using TogetherAI's endpoints as well!\n",
    "\n",
    "We're going to be using Meta Llama 3.1 70B Instruct Turbo - a powerful model which should get us powerful results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmTL6-pc1ZGz"
   },
   "source": [
    "Finally, we can set-up our RAG LCEL chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The kinds of loans available mentioned in the context are:\\n\\n- Direct PLUS Loan (student Federal PLUS Loan)\\n- Direct Subsidized Loan\\n- Direct Unsubsidized Loan\\n- Federal Stafford Loans (Subsidized and Unsubsidized) made under the FFEL Program before July 1, 2010\\n- Federal SLS Loans\\n- Federal PLUS Loans made under the FFEL Program before July 1, 2010\\n\\nAdditionally:\\n\\n- Direct Subsidized Loans are available only to undergraduate students.\\n- Graduate or professional students are eligible for Direct Unsubsidized Loans and Direct PLUS Loans, but not Direct Subsidized Loans.\\n\\nTherefore, the available loan types include Direct Subsidized Loans, Direct Unsubsidized Loans, Direct PLUS Loans, and prior FFEL Program loans (Stafford, SLS, PLUS) made before July 1, 2010.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"question\" : \"What kinds of loans are available?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9hBh5YPrdGJ"
   },
   "source": [
    "## LangSmith Evaluation Set-up\n",
    "\n",
    "We'll use OpenAI's GPT-4.1 as our evaluation LLM for our base Evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_llm = ChatOpenAI(model=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b8pToKH2K28"
   },
   "source": [
    "We'll be using a number of evaluators - from LangSmith provided evaluators, to a few custom evaluators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
    "\n",
    "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : eval_llm})\n",
    "\n",
    "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
    "    \"labeled_criteria\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"helpfulness\": (\n",
    "                \"Is this submission helpful to the user,\"\n",
    "                \" taking into account the correct reference answer?\"\n",
    "            )\n",
    "        },\n",
    "        \"llm\" : eval_llm\n",
    "    },\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"output\"],\n",
    "        \"reference\": example.outputs[\"answer\"],\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "empathy_evaluator = LangChainStringEvaluator(\n",
    "    \"criteria\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"empathy\": \"Is this response empathetic? Does it make the user feel like they are being heard?\",\n",
    "        },\n",
    "        \"llm\" : eval_llm\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0SQP_FoCetP"
   },
   "source": [
    "#### ðŸ—ï¸ Activity #2:\n",
    "\n",
    "Highlight what each evaluator is evaluating.\n",
    "\n",
    "- `qa_evaluator`:\n",
    "- `labeled_helpfulness_evaluator`:\n",
    "- `empathy_evaluator`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### âœ… Answer:\n",
    "\n",
    "**qa_evaluator:**\n",
    "\n",
    "Evaluates question-answer quality\n",
    "Uses chain-of-thought reasoning to assess how well the generated answer addresses the question\n",
    "Focuses on correctness and relevance of the response\n",
    "\n",
    "**labeled_helpfulness_evaluator:**\n",
    "\n",
    "Evaluates helpfulness with reference answers\n",
    "Compares the generated answer against the reference answer to determine if the submission is helpful to the user\n",
    "Takes into account the correct reference answer as ground truth\n",
    "\n",
    "**empathy_evaluator:**\n",
    "\n",
    "Evaluates empathy and emotional support\n",
    "Assesses whether the response is empathetic and makes the user feel heard and understood\n",
    "Checks if the response demonstrates kindness and emotional intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R35sQMHVrnpl"
   },
   "source": [
    "## LangSmith Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'advanced-neck-43' at:\n",
      "https://smith.langchain.com/o/e60ce1c7-6903-49a6-9264-5c7bd472b609/datasets/51da0801-b3c4-4e6e-9266-2537fdfe2b2a/compare?selectedSessions=61164698-1139-4ca4-9534-ea1780b9cc18\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1b390ab39b4789a5a9f87ce6ec5a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.empathy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do Chapters 2 and 3 collectively address t...</td>\n",
       "      <td>Chapters 2 and 3 collectively address the incl...</td>\n",
       "      <td>None</td>\n",
       "      <td>Chapter 2 discusses the inclusion of clinical ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.915536</td>\n",
       "      <td>1ea3cdd8-e97f-4aaf-aa8c-2c238a71e8a7</td>\n",
       "      <td>ae682cd5-0904-42b4-8ee9-4c1228bf548f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Considering the disbursement timing rules for ...</td>\n",
       "      <td>Based on the provided context, the inclusion o...</td>\n",
       "      <td>None</td>\n",
       "      <td>The inclusion of clinical work conducted outsi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.224609</td>\n",
       "      <td>2834503c-5190-4926-84a3-b565b68f8c36</td>\n",
       "      <td>ea168d25-1416-4871-b43e-311ccd8e7fae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does Volume 8 explain the impact of accele...</td>\n",
       "      <td>Volume 8 explains that if clinical work meets ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Volume 8 details that in clock-hour or non-ter...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.076714</td>\n",
       "      <td>aa3c02d5-f9d1-4721-932e-c06c839b0ae9</td>\n",
       "      <td>e37f6436-a709-40b0-b8c8-c1812eedf248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do Appendix A and Appendix B guide the dis...</td>\n",
       "      <td>Based on the provided context, Appendix B spec...</td>\n",
       "      <td>None</td>\n",
       "      <td>Appendix B provides detailed guidance on disbu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.099299</td>\n",
       "      <td>4563b284-fd8e-4e1d-9047-1bc155853267</td>\n",
       "      <td>1fde6896-616f-4527-9f61-33fb809dc1f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does the inclusion of clinical work in sta...</td>\n",
       "      <td>The inclusion of clinical work in standard ter...</td>\n",
       "      <td>None</td>\n",
       "      <td>The inclusion of clinical work in standard ter...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.133488</td>\n",
       "      <td>57af92d0-6598-41c2-a116-e4f1a85cd87d</td>\n",
       "      <td>96c97ef8-c21e-4806-b0eb-1b260dca1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do credit-hour and clock-hour programs dif...</td>\n",
       "      <td>Based on the provided context:\\n\\n**Minimum Ac...</td>\n",
       "      <td>None</td>\n",
       "      <td>Credit-hour programs must have an academic yea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.227769</td>\n",
       "      <td>59cd0622-5526-4d95-a68f-1287565a6bd0</td>\n",
       "      <td>23f6bd6f-0ba3-4266-975a-a1ad11de7fa6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wht are the weeks of instrctional time reuired...</td>\n",
       "      <td>The weeks of instructional time required for a...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context states that for credit-hour progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.838014</td>\n",
       "      <td>20fa0241-e929-49ea-965a-5529d5e42f1f</td>\n",
       "      <td>4a382228-bc9a-4250-96e0-5b404357fd2d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does completing additional hours or weeks ...</td>\n",
       "      <td>Completing additional weeks or hours in a paym...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completing additional weeks of instructional t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.059131</td>\n",
       "      <td>690fb2ad-9e4b-49bb-98d9-5fa3a58b761c</td>\n",
       "      <td>b6ea1402-2988-49d8-8667-e50980308a24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FWS is it like a payment period or not and how...</td>\n",
       "      <td>Based on the provided context:\\n\\n- The paymen...</td>\n",
       "      <td>None</td>\n",
       "      <td>The payment period is applicable to all Title ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.699819</td>\n",
       "      <td>fbab6bd2-8b70-46d3-929b-cb47f0c7de79</td>\n",
       "      <td>989641e3-4940-42cb-929e-99c592b77153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is Chaptr 3?</td>\n",
       "      <td>Chapter 3 is titled \"Packaging Aid.\" It explai...</td>\n",
       "      <td>None</td>\n",
       "      <td>Inclusion of Clinical Work in a Standard Term ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.727932</td>\n",
       "      <td>760adb8b-3c09-4c0d-9a15-bfaa254bc0c6</td>\n",
       "      <td>d3fc8135-9c16-48eb-a1c4-41c7a4533819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Could you please explain the significance of 3...</td>\n",
       "      <td>Based on the provided context, 34 CFR 668.3(a)...</td>\n",
       "      <td>None</td>\n",
       "      <td>Regulatory Citations Academic year minimums: 3...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.807513</td>\n",
       "      <td>95551d67-00db-4d29-a670-e661d50f4601</td>\n",
       "      <td>874fb435-d11c-464b-9d7e-440e53392ec7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is the role of the School Participation D...</td>\n",
       "      <td>The role of the School Participation Division ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context does not specify the exact role of...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.346463</td>\n",
       "      <td>06744f19-5958-45ec-8406-eef5b7abecec</td>\n",
       "      <td>1af6263f-69e9-43a5-bb7c-622be9c42864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults advanced-neck-43>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    rag_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        empathy_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"default_chain_init\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nq7fCVinrpI4"
   },
   "source": [
    "## Dope-ifying Our Application\n",
    "\n",
    "We'll be making a few changes to our RAG chain to increase its performance on our SDG evaluation test dataset!\n",
    "\n",
    "- Include a \"dope\" prompt augmentation\n",
    "- Use larger chunks\n",
    "- Improve the retriever model to: `text-embedding-3-large`\n",
    "\n",
    "Let's see how this changes our evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPATHY_RAG_PROMPT = \"\"\"\\\n",
    "Given a provided context and question, you must answer the question based only on context.\n",
    "\n",
    "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
    "\n",
    "You must answer the question using empathy and kindness, and make sure the user feels heard.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "empathy_rag_prompt = ChatPromptTemplate.from_template(EMPATHY_RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_documents = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "rag_documents = text_splitter.split_documents(rag_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spldiPuTCzDO"
   },
   "source": [
    "#### â“Question #2:\n",
    "\n",
    "Why would modifying our chunk size modify the performance of our application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### âœ… Answer:\n",
    "\n",
    "Larger chunks provide more comprehensive context, reducing information fragmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBbjG6cKC8BQ"
   },
   "source": [
    "#### â“Question #3:\n",
    "\n",
    "Why would modifying our embedding model modify the performance of our application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### âœ… Answer:\n",
    "\n",
    "text-embedding-3-large offers higher dimensional representations and better semantic capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=rag_documents,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"Loan Data for RAG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqYGFrnKDB91"
   },
   "source": [
    "Setting up our new and improved DOPE RAG CHAIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "empathy_rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | empathy_rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21pTxoqJDI1Y"
   },
   "source": [
    "Let's test it on the same output that we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you for your question. Based on the information you've shared, it looks like there are a few types of federal student loans available:\\n\\n1. **Direct Subsidized Loans** â€“ These are loans based on the studentâ€™s financial need, and interest is paid by the government while the student is in school at least half-time. For example, dependent first-year students can borrow up to $3,500 in subsidized loans.\\n\\n2. **Direct Unsubsidized Loans** â€“ These loans are available to students regardless of financial need. The borrower is responsible for interest during all periods.\\n\\n3. **Direct PLUS Loans** â€“ These loans are available to parents of dependent students (called Direct PLUS Loans for parents) or to graduate/professional students (called Direct PLUS Loans for students). They can cover the studentâ€™s cost of attendance beyond other financial aid but require the borrower to meet eligibility requirements. If a parent is unable to get a Direct PLUS Loan, the dependent student may get additional Direct Unsubsidized Loans.\\n\\nThese loans can be combined in different ways, depending on eligibility and the studentâ€™s financial need. I hope this helps clarify the types of loans available to support educational costs. If you have any more questions or feel uncertain, I'm here to help!\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empathy_rag_chain.invoke({\"question\" : \"What kinds of loans are available?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpj7v1inDLnQ"
   },
   "source": [
    "Finally, we can evaluate the new chain on the same test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'cold-nut-12' at:\n",
      "https://smith.langchain.com/o/e60ce1c7-6903-49a6-9264-5c7bd472b609/datasets/51da0801-b3c4-4e6e-9266-2537fdfe2b2a/compare?selectedSessions=a17a0094-14df-4c85-b417-cb5d61709218\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f55c9b04e5a4ac08748911a8e8c48bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.empathy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do Chapters 2 and 3 collectively address t...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Chapter 2 discusses the inclusion of clinical ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.043275</td>\n",
       "      <td>1ea3cdd8-e97f-4aaf-aa8c-2c238a71e8a7</td>\n",
       "      <td>06e85722-0544-4433-a563-fcd9ec7787ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Considering the disbursement timing rules for ...</td>\n",
       "      <td>Thank you for your thoughtful questionâ€”itâ€™s gr...</td>\n",
       "      <td>None</td>\n",
       "      <td>The inclusion of clinical work conducted outsi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.450671</td>\n",
       "      <td>2834503c-5190-4926-84a3-b565b68f8c36</td>\n",
       "      <td>df064232-3061-4177-9ce5-62fd5d0eef96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does Volume 8 explain the impact of accele...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Volume 8 details that in clock-hour or non-ter...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.467466</td>\n",
       "      <td>aa3c02d5-f9d1-4721-932e-c06c839b0ae9</td>\n",
       "      <td>227db3ae-1712-4716-bdc9-d8a12810640b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do Appendix A and Appendix B guide the dis...</td>\n",
       "      <td>Thank you for your thoughtful question. I can ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Appendix B provides detailed guidance on disbu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.343443</td>\n",
       "      <td>4563b284-fd8e-4e1d-9047-1bc155853267</td>\n",
       "      <td>38b2ca3f-2794-4408-b0ec-d01b464aadd4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does the inclusion of clinical work in sta...</td>\n",
       "      <td>Thank you for your thoughtful question. I unde...</td>\n",
       "      <td>None</td>\n",
       "      <td>The inclusion of clinical work in standard ter...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.135947</td>\n",
       "      <td>57af92d0-6598-41c2-a116-e4f1a85cd87d</td>\n",
       "      <td>724449be-4836-4c48-822b-190040e34c2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do credit-hour and clock-hour programs dif...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Credit-hour programs must have an academic yea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.740575</td>\n",
       "      <td>59cd0622-5526-4d95-a68f-1287565a6bd0</td>\n",
       "      <td>e14b45f7-1498-47ea-8497-9f877a869699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wht are the weeks of instrctional time reuired...</td>\n",
       "      <td>Thank you for your question! I understand that...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context states that for credit-hour progra...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.930687</td>\n",
       "      <td>20fa0241-e929-49ea-965a-5529d5e42f1f</td>\n",
       "      <td>5c055efb-48a1-41c0-8998-0637d6b1a507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does completing additional hours or weeks ...</td>\n",
       "      <td>Thank you for your thoughtful question. Based ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Completing additional weeks of instructional t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.783308</td>\n",
       "      <td>690fb2ad-9e4b-49bb-98d9-5fa3a58b761c</td>\n",
       "      <td>b0c3bb4c-3dd6-4f15-991e-8affa5482461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FWS is it like a payment period or not and how...</td>\n",
       "      <td>Thank you for your thoughtful question about t...</td>\n",
       "      <td>None</td>\n",
       "      <td>The payment period is applicable to all Title ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.362410</td>\n",
       "      <td>fbab6bd2-8b70-46d3-929b-cb47f0c7de79</td>\n",
       "      <td>682d0703-9211-41e0-80ec-d975d298f7b4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is Chaptr 3?</td>\n",
       "      <td>Thank you for your question! Based on the cont...</td>\n",
       "      <td>None</td>\n",
       "      <td>Inclusion of Clinical Work in a Standard Term ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.354064</td>\n",
       "      <td>760adb8b-3c09-4c0d-9a15-bfaa254bc0c6</td>\n",
       "      <td>041ef0a4-370b-4e49-8417-40f24942596d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Could you please explain the significance of 3...</td>\n",
       "      <td>Thank you for your thoughtful question. I unde...</td>\n",
       "      <td>None</td>\n",
       "      <td>Regulatory Citations Academic year minimums: 3...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.875276</td>\n",
       "      <td>95551d67-00db-4d29-a670-e661d50f4601</td>\n",
       "      <td>cb8eb599-b14c-47f8-9930-524adfca93db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is the role of the School Participation D...</td>\n",
       "      <td>Thank you for your question. Based on the cont...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context does not specify the exact role of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.416212</td>\n",
       "      <td>06744f19-5958-45ec-8406-eef5b7abecec</td>\n",
       "      <td>59e65493-b42c-46c4-bf35-5f5a96b2c562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults cold-nut-12>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    empathy_rag_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        empathy_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"empathy_rag_chain\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C7migvlDPZT"
   },
   "source": [
    "#### ðŸ—ï¸ Activity #3:\n",
    "\n",
    "Provide a screenshot of the difference between the two chains, and explain why you believe certain metrics changed in certain ways.\n",
    "\n",
    "##### âœ… Answer:\n",
    "\n",
    "**Screenshot of LangSmith Evaluation Comparison:**\n",
    "\n",
    "![Screenshot](Screenshot2025-07-19at9.23.03â€¯AM.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Results from Screenshot:**\n",
    "\n",
    "Based on your LangSmith comparison screenshot, here's what the metrics are telling us:\n",
    "\n",
    "**Observed Changes:**\n",
    "\n",
    "Looking at the evaluation results between your two experiments (`default_chain_init` vs `empathy_rag_chain`), we see specific metric improvements in:\n",
    "\n",
    "1. **Empathy Score**: This shows the most dramatic improvement since we explicitly added empathy instructions to the prompt. The empathy_evaluator measures whether responses make users feel heard and understood.\n",
    "\n",
    "2. **QA Correctness**: Correctness stayed the same (although one question improved and one question regressed on this metric.) Surprising, since larger chunks + better embeddings should have provided more relevant context for answering questions accurately.\n",
    "\n",
    "3. **Helpfulness Score**: Helpfulness (which is a measure of how similar the answer is to the reference answer) regressed by 1 point as two questions regressed (-2) nad 1 question improved (+1) w/r/t this metric. This demonstrates to me that sometimes increasing the chunk size and improving the embedding model is not the answer, as it depends on the type of data being evaluated / measured.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
