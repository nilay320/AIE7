{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCk2Rx4cjlYF"
   },
   "source": [
    "# Synthetic Data Generation Using RAGAS - RAG Evaluation with LangSmith\n",
    "\n",
    "In the following notebook we'll explore a use-case for RAGAS' synthetic testset generation workflow!\n",
    "\n",
    "\n",
    "\n",
    "- ðŸ¤ BREAKOUT ROOM #1\n",
    "  1. Use RAGAS to Generate Synthetic Data\n",
    "\n",
    "- ðŸ¤ BREAKOUT ROOM #2\n",
    "  1. Load them into a LangSmith Dataset\n",
    "  2. Evaluate our RAG chain against the synthetic test data\n",
    "  3. Make changes to our pipeline\n",
    "  4. Evaluate the modified pipeline\n",
    "\n",
    "SDG is a critical piece of the puzzle, especially for early iteration! Without it, it would not be nearly as easy to get high quality early signal for our application's performance.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bG2ta-B478G"
   },
   "source": [
    "# ðŸ¤ BREAKOUT ROOM #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VUI7vF_kbv9"
   },
   "source": [
    "## Task 1: Dependencies and API Keys\n",
    "\n",
    "We'll need to install a number of API keys and dependencies, since we'll be leveraging a number of great technologies for this pipeline!\n",
    "\n",
    "1. OpenAI's endpoints to handle the Synthetic Data Generation\n",
    "2. OpenAI's Endpoints for our RAG pipeline and LangSmith evaluation\n",
    "3. QDrant as our vectorstore\n",
    "4. LangSmith for our evaluation coordinator!\n",
    "\n",
    "Let's install and provide all the required information below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and API Keys:\n",
    "\n",
    "> NOTE: DO NOT RUN THESE CELLS IF YOU ARE RUNNING THIS NOTEBOOK LOCALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m175.7/175.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install -qU ragas==0.2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU langchain-community==0.3.14 langchain-openai==0.2.14 unstructured==0.16.12 langgraph==0.2.61 langchain-qdrant==0.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Import\n",
    "\n",
    "To prevent errors that may occur based on OS - we'll import NLTK and download the needed packages to ensure correct handling of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nilayjhaveri/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nilayjhaveri/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also want to set a project name to make things easier for ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - SDG - {uuid4().hex[0:8]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI's API Key!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Test Data\n",
    "\n",
    "We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n",
    "\n",
    "> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "We'll prepare our data - which should hopefull be familiar at this point since it's our Loan Data use-case!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "\n",
    "path = \"data/\"\n",
    "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph Based Synthetic Generation\n",
    "\n",
    "Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n",
    "\n",
    "Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrolled SDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nilayjhaveri/Workspace/Projects/ai_maker_space/ai_engineering/code/AIE7/07_Synthetic_Data_Generation_and_LangSmith/.venv/lib/python3.13/site-packages/pysbd/segmenter.py:66: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  for match in re.finditer('{0}\\s*'.format(re.escape(sent)), self.original_text):\n",
      "/Users/nilayjhaveri/Workspace/Projects/ai_maker_space/ai_engineering/code/AIE7/07_Synthetic_Data_Generation_and_LangSmith/.venv/lib/python3.13/site-packages/pysbd/lang/arabic.py:29: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  txt = re.sub('(?<={0})\\.'.format(am), 'âˆ¯', txt)\n",
      "/Users/nilayjhaveri/Workspace/Projects/ai_maker_space/ai_engineering/code/AIE7/07_Synthetic_Data_Generation_and_LangSmith/.venv/lib/python3.13/site-packages/pysbd/lang/persian.py:29: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  txt = re.sub('(?<={0})\\.'.format(am), 'âˆ¯', txt)\n"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to instantiate our Knowledge Graph.\n",
    "\n",
    "This graph will contain N number of nodes that have M number of relationships. These nodes and relationships (AKA \"edges\") will define our knowledge graph and be used later to construct relevant questions and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 0, relationships: 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step we're going to take is to simply insert each of our full documents into the graph. This will provide a base that we can apply transformations to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 20, relationships: 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "### NOTICE: We're using a subset of the data for this example - this is to keep costs/time down.\n",
    "for doc in docs[:20]:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll apply the *default* transformations to our knowledge graph. This will take the nodes currently on the graph and transform them based on a set of [default transformations](https://docs.ragas.io/en/latest/references/transforms/#ragas.testset.transforms.default_transforms).\n",
    "\n",
    "These default transformations are dependent on the corpus length, in our case:\n",
    "\n",
    "- Producing Summaries -> produces summaries of the documents\n",
    "- Extracting Headlines -> finding the overall headline for the document\n",
    "- Theme Extractor -> extracts broad themes about the documents\n",
    "\n",
    "It then uses cosine-similarity and heuristics between the embeddings of the above transformations to construct relationships between the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1326c335d634d14824988aba3dbdf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'headlines' already exists in node '0a6eb5'. Skipping!\n",
      "Property 'headlines' already exists in node '88e1c2'. Skipping!\n",
      "Property 'headlines' already exists in node '5cc3be'. Skipping!\n",
      "Property 'headlines' already exists in node '560d4d'. Skipping!\n",
      "Property 'headlines' already exists in node '4c4fb5'. Skipping!\n",
      "Property 'headlines' already exists in node '4b6de0'. Skipping!\n",
      "Property 'headlines' already exists in node 'd83507'. Skipping!\n",
      "Property 'headlines' already exists in node 'fc81ce'. Skipping!\n",
      "Property 'headlines' already exists in node '0af6fc'. Skipping!\n",
      "Property 'headlines' already exists in node '2bd9be'. Skipping!\n",
      "Property 'headlines' already exists in node 'f3310e'. Skipping!\n",
      "Property 'headlines' already exists in node 'adfac5'. Skipping!\n",
      "Property 'headlines' already exists in node 'f24c39'. Skipping!\n",
      "Property 'headlines' already exists in node '4ea684'. Skipping!\n",
      "Property 'headlines' already exists in node '8b7577'. Skipping!\n",
      "Property 'headlines' already exists in node '671737'. Skipping!\n",
      "Property 'headlines' already exists in node '671737'. Skipping!\n",
      "Property 'headlines' already exists in node '88e1c2'. Skipping!\n",
      "Property 'headlines' already exists in node 'd83507'. Skipping!\n",
      "Property 'headlines' already exists in node '8b7577'. Skipping!\n",
      "Property 'headlines' already exists in node 'adfac5'. Skipping!\n",
      "Property 'headlines' already exists in node 'f24c39'. Skipping!\n",
      "Property 'headlines' already exists in node '4ea684'. Skipping!\n",
      "Property 'headlines' already exists in node '4b6de0'. Skipping!\n",
      "Property 'headlines' already exists in node 'fc81ce'. Skipping!\n",
      "Property 'headlines' already exists in node '2bd9be'. Skipping!\n",
      "Property 'headlines' already exists in node 'f3310e'. Skipping!\n",
      "Property 'headlines' already exists in node '0af6fc'. Skipping!\n",
      "Property 'headlines' already exists in node '4c4fb5'. Skipping!\n",
      "Property 'headlines' already exists in node '3419e3'. Skipping!\n",
      "Property 'headlines' already exists in node '3419e3'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d893363bdb24edf88eff75e4e0a5e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ac900d11b94e9d8d2c7848c0fa2e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '0a6eb5'. Skipping!\n",
      "Property 'summary' already exists in node 'adfac5'. Skipping!\n",
      "Property 'summary' already exists in node '4ea684'. Skipping!\n",
      "Property 'summary' already exists in node '671737'. Skipping!\n",
      "Property 'summary' already exists in node '2bd9be'. Skipping!\n",
      "Property 'summary' already exists in node '4b6de0'. Skipping!\n",
      "Property 'summary' already exists in node '8b7577'. Skipping!\n",
      "Property 'summary' already exists in node '5cc3be'. Skipping!\n",
      "Property 'summary' already exists in node 'f3310e'. Skipping!\n",
      "Property 'summary' already exists in node '4c4fb5'. Skipping!\n",
      "Property 'summary' already exists in node '560d4d'. Skipping!\n",
      "Property 'summary' already exists in node 'fc81ce'. Skipping!\n",
      "Property 'summary' already exists in node '0af6fc'. Skipping!\n",
      "Property 'summary' already exists in node 'f24c39'. Skipping!\n",
      "Property 'summary' already exists in node 'd83507'. Skipping!\n",
      "Property 'summary' already exists in node '88e1c2'. Skipping!\n",
      "Property 'summary' already exists in node '3419e3'. Skipping!\n",
      "Property 'summary' already exists in node '88e1c2'. Skipping!\n",
      "Property 'summary' already exists in node 'fc81ce'. Skipping!\n",
      "Property 'summary' already exists in node 'adfac5'. Skipping!\n",
      "Property 'summary' already exists in node '4c4fb5'. Skipping!\n",
      "Property 'summary' already exists in node '671737'. Skipping!\n",
      "Property 'summary' already exists in node 'f3310e'. Skipping!\n",
      "Property 'summary' already exists in node '0af6fc'. Skipping!\n",
      "Property 'summary' already exists in node '2bd9be'. Skipping!\n",
      "Property 'summary' already exists in node '4ea684'. Skipping!\n",
      "Property 'summary' already exists in node 'd83507'. Skipping!\n",
      "Property 'summary' already exists in node '8b7577'. Skipping!\n",
      "Property 'summary' already exists in node 'f24c39'. Skipping!\n",
      "Property 'summary' already exists in node '3419e3'. Skipping!\n",
      "Property 'summary' already exists in node '4b6de0'. Skipping!\n",
      "Property 'summary' already exists in node '88e1c2'. Skipping!\n",
      "Property 'summary' already exists in node '671737'. Skipping!\n",
      "Property 'summary' already exists in node 'adfac5'. Skipping!\n",
      "Property 'summary' already exists in node 'd83507'. Skipping!\n",
      "Property 'summary' already exists in node 'fc81ce'. Skipping!\n",
      "Property 'summary' already exists in node '88e1c2'. Skipping!\n",
      "Property 'summary' already exists in node '2bd9be'. Skipping!\n",
      "Property 'summary' already exists in node '3419e3'. Skipping!\n",
      "Property 'summary' already exists in node '4ea684'. Skipping!\n",
      "Property 'summary' already exists in node '8b7577'. Skipping!\n",
      "Property 'summary' already exists in node 'f3310e'. Skipping!\n",
      "Property 'summary' already exists in node 'f24c39'. Skipping!\n",
      "Property 'summary' already exists in node '4c4fb5'. Skipping!\n",
      "Property 'summary' already exists in node '0af6fc'. Skipping!\n",
      "Property 'summary' already exists in node '4b6de0'. Skipping!\n",
      "Property 'summary' already exists in node '671737'. Skipping!\n",
      "Property 'summary' already exists in node 'd83507'. Skipping!\n",
      "Property 'summary' already exists in node 'f24c39'. Skipping!\n",
      "Property 'summary' already exists in node 'fc81ce'. Skipping!\n",
      "Property 'summary' already exists in node 'adfac5'. Skipping!\n",
      "Property 'summary' already exists in node '0af6fc'. Skipping!\n",
      "Property 'summary' already exists in node '2bd9be'. Skipping!\n",
      "Property 'summary' already exists in node '4ea684'. Skipping!\n",
      "Property 'summary' already exists in node '8b7577'. Skipping!\n",
      "Property 'summary' already exists in node 'f3310e'. Skipping!\n",
      "Property 'summary' already exists in node '4c4fb5'. Skipping!\n",
      "Property 'summary' already exists in node '4b6de0'. Skipping!\n",
      "Property 'summary' already exists in node '3419e3'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f75d0bc6b54ef0948fa51bfdc14121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f6cd8035ad4293851f5e7c301858d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node '88e1c2'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '0a6eb5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '671737'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd83507'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f24c39'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4ea684'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '0af6fc'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'adfac5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '5cc3be'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '2bd9be'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8b7577'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4c4fb5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4b6de0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '560d4d'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'fc81ce'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f3310e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3419e3'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '88e1c2'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '671737'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd83507'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f24c39'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4ea684'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '0af6fc'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'adfac5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '2bd9be'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8b7577'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4c4fb5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4b6de0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'fc81ce'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f3310e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3419e3'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '88e1c2'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '671737'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd83507'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f24c39'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4ea684'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '0af6fc'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'adfac5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '2bd9be'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8b7577'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4c4fb5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4b6de0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'fc81ce'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f3310e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3419e3'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '88e1c2'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '671737'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd83507'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f24c39'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4ea684'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '0af6fc'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'adfac5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '2bd9be'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8b7577'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4c4fb5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4b6de0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'fc81ce'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f3310e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3419e3'. Skipping!\n",
      "Property 'entities' already exists in node 'de94ff'. Skipping!\n",
      "Property 'entities' already exists in node 'dc66e9'. Skipping!\n",
      "Property 'entities' already exists in node 'b1889a'. Skipping!\n",
      "Property 'themes' already exists in node '0ad9c9'. Skipping!\n",
      "Property 'themes' already exists in node 'de94ff'. Skipping!\n",
      "Property 'themes' already exists in node 'f4d09a'. Skipping!\n",
      "Property 'themes' already exists in node 'dc66e9'. Skipping!\n",
      "Property 'entities' already exists in node 'd2a3d6'. Skipping!\n",
      "Property 'entities' already exists in node 'f4d09a'. Skipping!\n",
      "Property 'entities' already exists in node '0ad9c9'. Skipping!\n",
      "Property 'themes' already exists in node 'd2a3d6'. Skipping!\n",
      "Property 'themes' already exists in node 'b1889a'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2493b45880f5487c955385967260303e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 74, relationships: 2220)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "transformer_llm = generator_llm\n",
    "embedding_model = generator_embeddings\n",
    "\n",
    "default_transforms = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n",
    "apply_transforms(kg, default_transforms)\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save and load our knowledge graphs as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 74, relationships: 2220)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.save(\"loan_data_kg.json\")\n",
    "loan_data_kg = KnowledgeGraph.load(\"loan_data_kg.json\")\n",
    "loan_data_kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our knowledge graph, we can construct a \"test set generator\" - which will allow us to create queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=loan_data_kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we'd like to be able to define the kinds of queries we're generating - which is made simple by Ragas having pre-created a number of different \"QuerySynthesizer\"s.\n",
    "\n",
    "Each of these Synthetsizers is going to tackle a separate kind of query which will be generated from a scenario and a persona.\n",
    "\n",
    "In essence, Ragas will use an LLM to generate a persona of someone who would interact with the data - and then use a scenario to construct a question from that data and persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import default_query_distribution, SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
    "\n",
    "query_distribution = [\n",
    "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "        (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "        (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### â“ Question #1:\n",
    "\n",
    "What are the three types of query synthesizers doing? Describe each one in simple terms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### âœ… Answer:\n",
    "Review:\n",
    "\n",
    "SingleHopSpecificQuerySynthesizer - This generates straightforward, direct queries that can be answered with a single step or \"hop\" through the data. These are specific, focused questions that don't require complex reasoning or multiple data points to answer.\n",
    "MultiHopAbstractQuerySynthesizer - This creates more complex queries that require multiple steps or \"hops\" to answer, but the questions are abstract in nature. These queries might need to connect different pieces of information or require higher-level reasoning to resolve.\n",
    "MultiHopSpecificQuerySynthesizer - This generates complex queries that require multiple steps to answer, but unlike the abstract version, these queries are specific and concrete. They need multiple data points or reasoning steps but ask for precise, specific information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use our `TestSetGenerator` to generate our testset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db83f10f404746979392dd393a099ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305ea983b29c4bf1b6296aff6d648b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of the Knowledge Center?</td>\n",
       "      <td>[Chapter 1 Academic Years, Academic Calendars,...</td>\n",
       "      <td>The context does not specify the purpose of th...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you please explain the significance of 3...</td>\n",
       "      <td>[Regulatory Citations Academic year minimums: ...</td>\n",
       "      <td>Regulatory Citations Academic year minimums: 3...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the context of Chapter 3, how does inclusio...</td>\n",
       "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
       "      <td>Inclusion of clinical work in a standard term ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are Non-Term Characteristics in academic ...</td>\n",
       "      <td>[Non-Term Characteristics A program that measu...</td>\n",
       "      <td>A program that measures progress in clock hour...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the purpose of Appendix A?</td>\n",
       "      <td>[both the credit or clock hours and the weeks ...</td>\n",
       "      <td>Appendix A provides examples illustrating how ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does the inclusion of clinical work in sta...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>The inclusion of clinical work in standard ter...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wht are the instrucional time and weeks of ins...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nChapter 1 Academic Years, Academic...</td>\n",
       "      <td>The regulatons specify that for credit hour pr...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do the regulatory citations in 34 CFR 668....</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nChapter 1 Academic Years, Academic...</td>\n",
       "      <td>The regulatory citations in 34 CFR 668.3(a) an...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does the inclusion of clinical work in a s...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>According to Volume 8, if clinical work meets ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How do the definitions of academic years in Vo...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>Volume 2 specifies that an academic year must ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does the inclusion of clinical work in sta...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>The inclusion of clinical work in standard ter...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0        What is the purpose of the Knowledge Center?   \n",
       "1   Could you please explain the significance of 3...   \n",
       "2   In the context of Chapter 3, how does inclusio...   \n",
       "3   What are Non-Term Characteristics in academic ...   \n",
       "4                  What is the purpose of Appendix A?   \n",
       "5   How does the inclusion of clinical work in sta...   \n",
       "6   Wht are the instrucional time and weeks of ins...   \n",
       "7   How do the regulatory citations in 34 CFR 668....   \n",
       "8   How does the inclusion of clinical work in a s...   \n",
       "9   How do the definitions of academic years in Vo...   \n",
       "10  How does the inclusion of clinical work in sta...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Chapter 1 Academic Years, Academic Calendars,...   \n",
       "1   [Regulatory Citations Academic year minimums: ...   \n",
       "2   [Inclusion of Clinical Work in a Standard Term...   \n",
       "3   [Non-Term Characteristics A program that measu...   \n",
       "4   [both the credit or clock hours and the weeks ...   \n",
       "5   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "6   [<1-hop>\\n\\nChapter 1 Academic Years, Academic...   \n",
       "7   [<1-hop>\\n\\nChapter 1 Academic Years, Academic...   \n",
       "8   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "9   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "10  [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The context does not specify the purpose of th...   \n",
       "1   Regulatory Citations Academic year minimums: 3...   \n",
       "2   Inclusion of clinical work in a standard term ...   \n",
       "3   A program that measures progress in clock hour...   \n",
       "4   Appendix A provides examples illustrating how ...   \n",
       "5   The inclusion of clinical work in standard ter...   \n",
       "6   The regulatons specify that for credit hour pr...   \n",
       "7   The regulatory citations in 34 CFR 668.3(a) an...   \n",
       "8   According to Volume 8, if clinical work meets ...   \n",
       "9   Volume 2 specifies that an academic year must ...   \n",
       "10  The inclusion of clinical work in standard ter...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   single_hop_specifc_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstracted SDG\n",
    "\n",
    "The above method is the full process - but we can shortcut that using the provided abstractions!\n",
    "\n",
    "This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95378deae1e24a86a9a8ba37520d3e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39964161c27c4216af547f775c9ae9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9172444b0e1f4a7f9769a7dbd0531d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node 'c4e53f'. Skipping!\n",
      "Property 'summary' already exists in node 'a42deb'. Skipping!\n",
      "Property 'summary' already exists in node 'c51a37'. Skipping!\n",
      "Property 'summary' already exists in node '2209e9'. Skipping!\n",
      "Property 'summary' already exists in node 'c64367'. Skipping!\n",
      "Property 'summary' already exists in node '3674dc'. Skipping!\n",
      "Property 'summary' already exists in node 'ca83f0'. Skipping!\n",
      "Property 'summary' already exists in node '2a5461'. Skipping!\n",
      "Property 'summary' already exists in node '2af44a'. Skipping!\n",
      "Property 'summary' already exists in node '9cb0fd'. Skipping!\n",
      "Property 'summary' already exists in node 'fff614'. Skipping!\n",
      "Property 'summary' already exists in node 'b524f2'. Skipping!\n",
      "Property 'summary' already exists in node '1d5557'. Skipping!\n",
      "Property 'summary' already exists in node '36f4b0'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9497b25e47b4ef892ea9a55bb8e1b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc27ac5fb1f4d64b525ef8a994cb616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node 'c4e53f'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '2a5461'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ca83f0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'a42deb'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'c51a37'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'fff614'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '2af44a'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3674dc'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '2209e9'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '9cb0fd'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b524f2'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '36f4b0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'c64367'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '1d5557'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e466b361934847810d2a1c468f359a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da16d1daf3d49b2a2751f644562585d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5694c318044d47d195d9d022582208da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b30b74f12a437ba44b4ef3f8d9bfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs[:20], testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are academic years in the context of educ...</td>\n",
       "      <td>[Chapter 1 Academic Years, Academic Calendars,...</td>\n",
       "      <td>Academic years are defined as periods that inc...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is 34 CFR 668.3(a) about in academic year...</td>\n",
       "      <td>[Regulatory Citations Academic year minimums: ...</td>\n",
       "      <td>Regulatory Citations Academic year minimums: 3...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does Volume 8 specify about including cli...</td>\n",
       "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
       "      <td>Volume 8 states that clinical work conducted o...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is Title IV a term or non-term program?</td>\n",
       "      <td>[Non-Term Characteristics A program that measu...</td>\n",
       "      <td>According to the context, Title IV programs ar...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do the payment periods relate to the requi...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nChapter 1 Academic Years, Academic...</td>\n",
       "      <td>The payment periods are linked to the academic...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>how disbursmnt timing in subscrptn-based progr...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>The context explains that for the first two su...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do the guidelines and exceptions for clini...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>The guidelines specify that clinical work cond...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Considering the participation and requirements...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>Measuring progress in clock hours causes a pro...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do the definitions and requirements outlin...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nChapter 1 Academic Years, Academic...</td>\n",
       "      <td>The regulations in Volume 2 specify that an ac...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>where appendix A and B show disbursement timin...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
       "      <td>Appendix B provides detailed guidance and exam...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Volume 2 and Volume 8 what they say about clin...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>Volume 2 explains that clinical work conducted...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How does the inclusion of clinical work in a s...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>According to Volume 8, clinical work conducted...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   What are academic years in the context of educ...   \n",
       "1   What is 34 CFR 668.3(a) about in academic year...   \n",
       "2   What does Volume 8 specify about including cli...   \n",
       "3             Is Title IV a term or non-term program?   \n",
       "4   How do the payment periods relate to the requi...   \n",
       "5   how disbursmnt timing in subscrptn-based progr...   \n",
       "6   How do the guidelines and exceptions for clini...   \n",
       "7   Considering the participation and requirements...   \n",
       "8   How do the definitions and requirements outlin...   \n",
       "9   where appendix A and B show disbursement timin...   \n",
       "10  Volume 2 and Volume 8 what they say about clin...   \n",
       "11  How does the inclusion of clinical work in a s...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Chapter 1 Academic Years, Academic Calendars,...   \n",
       "1   [Regulatory Citations Academic year minimums: ...   \n",
       "2   [Inclusion of Clinical Work in a Standard Term...   \n",
       "3   [Non-Term Characteristics A program that measu...   \n",
       "4   [<1-hop>\\n\\nChapter 1 Academic Years, Academic...   \n",
       "5   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "6   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "7   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "8   [<1-hop>\\n\\nChapter 1 Academic Years, Academic...   \n",
       "9   [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
       "10  [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "11  [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   Academic years are defined as periods that inc...   \n",
       "1   Regulatory Citations Academic year minimums: 3...   \n",
       "2   Volume 8 states that clinical work conducted o...   \n",
       "3   According to the context, Title IV programs ar...   \n",
       "4   The payment periods are linked to the academic...   \n",
       "5   The context explains that for the first two su...   \n",
       "6   The guidelines specify that clinical work cond...   \n",
       "7   Measuring progress in clock hours causes a pro...   \n",
       "8   The regulations in Volume 2 specify that an ac...   \n",
       "9   Appendix B provides detailed guidance and exam...   \n",
       "10  Volume 2 explains that clinical work conducted...   \n",
       "11  According to Volume 8, clinical work conducted...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vSRr2MXk0P_"
   },
   "source": [
    "We'll need to provide our LangSmith API key, and set tracing to \"true\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLDUsLJg43k7"
   },
   "source": [
    "# ðŸ¤ BREAKOUT ROOM #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SLtk1GtnyoY"
   },
   "source": [
    "## Task 4: LangSmith Dataset\n",
    "\n",
    "Now we can move on to creating a dataset for LangSmith!\n",
    "\n",
    "First, we'll need to create a dataset on LangSmith using the `Client`!\n",
    "\n",
    "We'll name our Dataset to make it easy to work with later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"Loan Synthetic Data\"\n",
    "\n",
    "langsmith_dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Loan Synthetic Data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64SmXMBnzXWm"
   },
   "source": [
    "We'll iterate through the RAGAS created dataframe - and add each example to our created dataset!\n",
    "\n",
    "> NOTE: We need to conform the outputs to the expected format - which in this case is: `question` and `answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_row in dataset.to_pandas().iterrows():\n",
    "  client.create_example(\n",
    "      inputs={\n",
    "          \"question\": data_row[1][\"user_input\"]\n",
    "      },\n",
    "      outputs={\n",
    "          \"answer\": data_row[1][\"reference\"]\n",
    "      },\n",
    "      metadata={\n",
    "          \"context\": data_row[1][\"reference_contexts\"]\n",
    "      },\n",
    "      dataset_id=langsmith_dataset.id\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6EbQVyZq-2j"
   },
   "source": [
    "## Basic RAG Chain\n",
    "\n",
    "Time for some RAG!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_documents = docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQorBy8H1AZR"
   },
   "source": [
    "To keep things simple, we'll just use LangChain's recursive character text splitter!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "rag_documents = text_splitter.split_documents(rag_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kghuTb9R01oO"
   },
   "source": [
    "We'll create our vectorstore using OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpCLS-a01Ft2"
   },
   "source": [
    "As usual, we will power our RAG application with Qdrant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=rag_documents,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"Loan RAG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxUOMaQX1K2N"
   },
   "source": [
    "To get the \"A\" in RAG, we'll provide a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "Given a provided context and question, you must answer the question based only on context.\n",
    "\n",
    "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZnHDh4e1Ou5"
   },
   "source": [
    "For our LLM, we will be using TogetherAI's endpoints as well!\n",
    "\n",
    "We're going to be using Meta Llama 3.1 70B Instruct Turbo - a powerful model which should get us powerful results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmTL6-pc1ZGz"
   },
   "source": [
    "Finally, we can set-up our RAG LCEL chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The kinds of loans available include:\\n\\n- Direct Subsidized Loans (available only to undergraduate students)\\n- Direct Unsubsidized Loans  \\n- Direct PLUS Loans (also called student Federal PLUS Loans or parent PLUS Loans)\\n- Subsidized and Unsubsidized Federal Stafford Loans (made under the FFEL Program before it ended July 1, 2010)\\n- Federal SLS Loans (also made under the FFEL Program before July 1, 2010)\\n- Federal PLUS Loans (also made under the FFEL Program before July 1, 2010)\\n\\nAdditionally, there are Direct Consolidation Loans or Federal Consolidation Loans for borrowers who consolidate previous loans.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"question\" : \"What kinds of loans are available?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9hBh5YPrdGJ"
   },
   "source": [
    "## LangSmith Evaluation Set-up\n",
    "\n",
    "We'll use OpenAI's GPT-4.1 as our evaluation LLM for our base Evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_llm = ChatOpenAI(model=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b8pToKH2K28"
   },
   "source": [
    "We'll be using a number of evaluators - from LangSmith provided evaluators, to a few custom evaluators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
    "\n",
    "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : eval_llm})\n",
    "\n",
    "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
    "    \"labeled_criteria\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"helpfulness\": (\n",
    "                \"Is this submission helpful to the user,\"\n",
    "                \" taking into account the correct reference answer?\"\n",
    "            )\n",
    "        },\n",
    "        \"llm\" : eval_llm\n",
    "    },\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"output\"],\n",
    "        \"reference\": example.outputs[\"answer\"],\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "empathy_evaluator = LangChainStringEvaluator(\n",
    "    \"criteria\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"empathy\": \"Is this response empathetic? Does it make the user feel like they are being heard?\",\n",
    "        },\n",
    "        \"llm\" : eval_llm\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0SQP_FoCetP"
   },
   "source": [
    "#### ðŸ—ï¸ Activity #2:\n",
    "\n",
    "Highlight what each evaluator is evaluating.\n",
    "\n",
    "- `qa_evaluator`:\n",
    "- `labeled_helpfulness_evaluator`:\n",
    "- `empathy_evaluator`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n",
    "qa evaluator: evaluates question answer quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R35sQMHVrnpl"
   },
   "source": [
    "## LangSmith Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'passionate-thumb-48' at:\n",
      "https://smith.langchain.com/o/e60ce1c7-6903-49a6-9264-5c7bd472b609/datasets/d24cb98d-d826-4a47-b009-5657c937811e/compare?selectedSessions=aa3f31ff-27f3-485d-95c0-d5ca95d52059\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3609d739473746668c3952a6f123e701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.empathy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the inclusion of clinical work in a s...</td>\n",
       "      <td>The inclusion of clinical work in a standard t...</td>\n",
       "      <td>None</td>\n",
       "      <td>According to Volume 8, clinical work conducted...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.240797</td>\n",
       "      <td>8968ec86-0717-477e-af81-46454289711d</td>\n",
       "      <td>9100fdbf-6efa-4e8e-8467-971cfa3fb0c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Volume 2 and Volume 8 what they say about clin...</td>\n",
       "      <td>Based on the provided context:\\n\\n- **Volume 2...</td>\n",
       "      <td>None</td>\n",
       "      <td>Volume 2 explains that clinical work conducted...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.359624</td>\n",
       "      <td>584f7793-6354-433c-911f-43730a197df4</td>\n",
       "      <td>e79752af-ea1e-4bcb-9a00-a4acf0f29820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>where appendix A and B show disbursement timin...</td>\n",
       "      <td>Appendix B provides detailed guidance on the d...</td>\n",
       "      <td>None</td>\n",
       "      <td>Appendix B provides detailed guidance and exam...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.395603</td>\n",
       "      <td>8d364a02-b428-47ea-b471-a18ffc60a201</td>\n",
       "      <td>3a06ad78-2bc4-427f-bf99-0151b56d2e03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do the definitions and requirements outlin...</td>\n",
       "      <td>Based on the provided context:\\n\\nThe definiti...</td>\n",
       "      <td>None</td>\n",
       "      <td>The regulations in Volume 2 specify that an ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.844610</td>\n",
       "      <td>e808e069-ba6a-4749-9278-484acf13aa79</td>\n",
       "      <td>67fc02fd-13cf-4338-8143-275d59177df2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Considering the participation and requirements...</td>\n",
       "      <td>Measuring progress in clock hours always resul...</td>\n",
       "      <td>None</td>\n",
       "      <td>Measuring progress in clock hours causes a pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.237756</td>\n",
       "      <td>6088a0f8-7f26-4c59-affb-286f92dd5bed</td>\n",
       "      <td>5274b5ba-7e3d-4acc-a9c5-a7050cb8bd91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do the guidelines and exceptions for clini...</td>\n",
       "      <td>Based on the provided context, the guidelines ...</td>\n",
       "      <td>None</td>\n",
       "      <td>The guidelines specify that clinical work cond...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.448275</td>\n",
       "      <td>24983ca5-fb7b-4237-bd97-6a24faa1f87d</td>\n",
       "      <td>575fc7ba-0d43-44c9-86d5-d329c541af89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>how disbursmnt timing in subscrptn-based progr...</td>\n",
       "      <td>Based on the provided context:\\n\\nIn subscript...</td>\n",
       "      <td>None</td>\n",
       "      <td>The context explains that for the first two su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.332688</td>\n",
       "      <td>27d10777-6a2e-4c41-8492-067ab1954fdd</td>\n",
       "      <td>cedb3d58-df21-473f-93e0-8cd4a4e1c58b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do the payment periods relate to the requi...</td>\n",
       "      <td>Payment periods for different programs are def...</td>\n",
       "      <td>None</td>\n",
       "      <td>The payment periods are linked to the academic...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.538941</td>\n",
       "      <td>a96fea42-6df1-4964-9088-9141887d2eed</td>\n",
       "      <td>4758931c-e747-4199-a9bb-3c38b1b9308e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Is Title IV a term or non-term program?</td>\n",
       "      <td>Based on the context, Title IV funds can be ap...</td>\n",
       "      <td>None</td>\n",
       "      <td>According to the context, Title IV programs ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.738412</td>\n",
       "      <td>db67f6ba-6ff7-48b6-b3f3-9cc3df888781</td>\n",
       "      <td>6a3574cd-f1c0-48c2-b0d0-a60618def475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What does Volume 8 specify about including cli...</td>\n",
       "      <td>Volume 8, specifically Chapter 3, provides add...</td>\n",
       "      <td>None</td>\n",
       "      <td>Volume 8 states that clinical work conducted o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.318640</td>\n",
       "      <td>b7c64400-5853-4932-a759-645ecacae810</td>\n",
       "      <td>abad45cd-ba11-47e0-9250-5ef83c14d28f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is 34 CFR 668.3(a) about in academic year...</td>\n",
       "      <td>34 CFR 668.3(a) pertains to the academic year ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Regulatory Citations Academic year minimums: 3...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.444940</td>\n",
       "      <td>ce3a86a3-d895-4b70-b54d-de372561fb46</td>\n",
       "      <td>cca4fcf9-f643-40a7-894c-356e90cdbc27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What are academic years in the context of educ...</td>\n",
       "      <td>Academic years, in the context of educational ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Academic years are defined as periods that inc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.830035</td>\n",
       "      <td>ff8a2acd-8864-4ee9-8c3d-94b569a2450a</td>\n",
       "      <td>0de16355-e2d4-4bd7-b749-dce3c2ac353c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults passionate-thumb-48>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    rag_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        empathy_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"default_chain_init\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nq7fCVinrpI4"
   },
   "source": [
    "## Dope-ifying Our Application\n",
    "\n",
    "We'll be making a few changes to our RAG chain to increase its performance on our SDG evaluation test dataset!\n",
    "\n",
    "- Include a \"dope\" prompt augmentation\n",
    "- Use larger chunks\n",
    "- Improve the retriever model to: `text-embedding-3-large`\n",
    "\n",
    "Let's see how this changes our evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPATHY_RAG_PROMPT = \"\"\"\\\n",
    "Given a provided context and question, you must answer the question based only on context.\n",
    "\n",
    "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
    "\n",
    "You must answer the question using empathy and kindness, and make sure the user feels heard.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "empathy_rag_prompt = ChatPromptTemplate.from_template(EMPATHY_RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_documents = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "rag_documents = text_splitter.split_documents(rag_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spldiPuTCzDO"
   },
   "source": [
    "#### â“Question #2:\n",
    "\n",
    "Why would modifying our chunk size modify the performance of our application?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBbjG6cKC8BQ"
   },
   "source": [
    "#### â“Question #3:\n",
    "\n",
    "Why would modifying our embedding model modify the performance of our application?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=rag_documents,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"Loan Data for RAG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqYGFrnKDB91"
   },
   "source": [
    "Setting up our new and improved DOPE RAG CHAIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empathy_rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | empathy_rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21pTxoqJDI1Y"
   },
   "source": [
    "Let's test it on the same output that we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agents? Man, theyâ€™re this super vague concept in the AI world. Some folks think of them as digital assistants that act on your behalfâ€”like a travel agent. Others see them as AI models with tools, looping through tasks to solve problems. But hereâ€™s the kicker: the term is so fuzzy that it leaves you scratching your head, since everyone seems to have their own take on what it really means. Plus, thereâ€™s this whole issue of gullibilityâ€”how can these agents make smart choices if they canâ€™t tell reality from fiction? So yeah, theyâ€™re like this elusive dream still waiting for a real breakthrough. ðŸ’«'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empathy_rag_chain.invoke({\"question\" : \"What kinds of loans are available?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpj7v1inDLnQ"
   },
   "source": [
    "Finally, we can evaluate the new chain on the same test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'artistic-airplane-98' at:\n",
      "https://smith.langchain.com/o/117cfda3-8a09-4ba4-9922-07b45fd73803/datasets/25fa804e-0ce3-4848-9cd1-c83d91988e78/compare?selectedSessions=42ea0e06-22a8-4bfb-a5bc-760a0cf4d280\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72d571a85c4495db152af05ef004ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.dopeness</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How has the introduction of GPT-4o impacted th...</td>\n",
       "      <td>Yo, the rollout of GPT-4o is such a game chang...</td>\n",
       "      <td>None</td>\n",
       "      <td>The introduction of GPT-4o has significantly i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.590299</td>\n",
       "      <td>e749dc1c-f46a-4e61-9742-daa3d275671c</td>\n",
       "      <td>dffab390-a87b-4d08-93a3-8eedc7d24a7e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How did the breaking of the GPT-4 barrier in 2...</td>\n",
       "      <td>Yo, the breaking of the GPT-4 barrier in 2024 ...</td>\n",
       "      <td>None</td>\n",
       "      <td>In 2024, the breaking of the GPT-4 barrier sig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.217965</td>\n",
       "      <td>e0f5c6c4-fb8e-411e-8399-95212616c92b</td>\n",
       "      <td>d10800e7-981e-4127-8641-d2f357f52723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does the training efficiency of DeepSeek v...</td>\n",
       "      <td>Yo, check it! DeepSeek v3 is flexing some seri...</td>\n",
       "      <td>None</td>\n",
       "      <td>DeepSeek v3, a 685B parameter model, is one of...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.265255</td>\n",
       "      <td>28816b79-8c83-49b7-90f3-dc5a99ee6a7f</td>\n",
       "      <td>cddb24bd-3a3c-4ad3-9f10-cebb03122d05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How has the development of models surpassing G...</td>\n",
       "      <td>Yo, the scene in 2024 is pretty wild! With 18 ...</td>\n",
       "      <td>None</td>\n",
       "      <td>In 2024, the development of models surpassing ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.281109</td>\n",
       "      <td>757f3ec9-c32f-4d24-a2f7-d02b88fdb499</td>\n",
       "      <td>2fa50d79-687c-4902-a08c-9e603a4bab64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do the ethics of AI and the gullibility of...</td>\n",
       "      <td>Yo, the ethics of AI and the gullibility of la...</td>\n",
       "      <td>None</td>\n",
       "      <td>The ethics of AI and the gullibility of langua...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.492535</td>\n",
       "      <td>bf0ac2b1-9738-4e30-8f8b-1b5d9e8c3b04</td>\n",
       "      <td>56695a52-31b0-4ce8-bd7f-f071a3649b82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the ethical concerns related to the g...</td>\n",
       "      <td>Yo, the ethical vibes around the gullibility o...</td>\n",
       "      <td>None</td>\n",
       "      <td>The ethical concerns related to the gullibilit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.733880</td>\n",
       "      <td>d312a7f8-fd86-4df7-9d4d-6f9387a11412</td>\n",
       "      <td>32fe5cb2-0df4-4265-ad76-0487a7cbcb9f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Why are Large Language Models (LLMs) considere...</td>\n",
       "      <td>LLMs are considered black boxes because, despi...</td>\n",
       "      <td>None</td>\n",
       "      <td>Large Language Models (LLMs) are considered bl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.673780</td>\n",
       "      <td>28659332-3637-4cee-9018-98d587575f5b</td>\n",
       "      <td>6d4eece2-36ce-45e1-b308-11ab50b14f34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the ethical concerns associated with ...</td>\n",
       "      <td>Yo, the ethical vibes surrounding the gullibil...</td>\n",
       "      <td>None</td>\n",
       "      <td>The ethical concerns associated with the gulli...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.375634</td>\n",
       "      <td>2da5c189-eb9e-419b-9c93-e3247d9f154c</td>\n",
       "      <td>6b2701ac-8dd9-42bc-b4cf-92c410f43390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What role does Stanford Alpaca play in the dev...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>Stanford Alpaca is associated with the acceler...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.234988</td>\n",
       "      <td>1c5369b1-7b7e-476d-9d28-816ce1a360f6</td>\n",
       "      <td>4be48806-dee2-4810-9d3a-6a07e97d14ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Whaat are the key highlights from Simon Willis...</td>\n",
       "      <td>Yo, letâ€™s break it down! In 2023, Simon Willis...</td>\n",
       "      <td>None</td>\n",
       "      <td>Simon Willison's Weblog highlights that 2023 w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.724408</td>\n",
       "      <td>012f7bdc-73f0-4ad8-8a30-e89edbb0a0e7</td>\n",
       "      <td>2c0cd907-d3ed-452c-8bac-e5b3368a1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What significant event related to AI ethics oc...</td>\n",
       "      <td>Yo, in September last year, there was a major ...</td>\n",
       "      <td>None</td>\n",
       "      <td>In September last year, the term 'prompt injec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.863023</td>\n",
       "      <td>5719d5a1-4355-41b4-aabc-dd1c10357462</td>\n",
       "      <td>13719abd-f8cb-4d31-bf90-bb21317be497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wut has Meta dun in the feeld of LLMs this yeer?</td>\n",
       "      <td>Yo, Meta's been making waves in the LLM scene ...</td>\n",
       "      <td>None</td>\n",
       "      <td>In February, Meta released Llama, and in July,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.654334</td>\n",
       "      <td>dcc029aa-596c-44f0-89c4-c54fa92184ea</td>\n",
       "      <td>e319edf2-130c-4379-ac89-62a205a21ad0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults artistic-airplane-98>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    empathy_rag_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        empathy_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"empathy_rag_chain\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C7migvlDPZT"
   },
   "source": [
    "#### ðŸ—ï¸ Activity #3:\n",
    "\n",
    "Provide a screenshot of the difference between the two chains, and explain why you believe certain metrics changed in certain ways."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
